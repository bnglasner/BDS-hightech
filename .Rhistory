View(`1992patents`)
`1996patents` <- read.csv("~/Documents/1996patents.txt", sep="")
View(`1996patents`)
`2000patents` <- read.csv("~/Documents/2000patents.txt", sep="")
`1999patents` <- read.csv("~/Documents/1999patents.txt", sep="")
`1998patents` <- read.csv("~/Documents/1998patents.txt", sep="")
`1997patents` <- read.csv("~/Documents/1997patents.txt", sep="")
`1996patents` <- read.csv("~/Documents/1996patents.txt", sep="")
`1995patents` <- read.csv("~/Documents/1995patents.txt", sep="")
`1994patents` <- read.csv("~/Documents/1994patents.txt", sep="")
`1993patents` <- read.csv("~/Documents/1993patents.txt", sep="")
`1992patents` <- read.csv("~/Documents/1992patents.txt", sep="")
`2000patents` <- read.csv("~/Documents/2000patents.txt", sep="")
`1999patents` <- read.csv("~/Documents/1999patents.txt", sep="")
`1998patents` <- read.csv("~/Documents/1998patents.txt", sep="")
`1997patents` <- read.csv("~/Documents/1997patents.txt", sep="")
`1996patents` <- read.csv("~/Documents/1996patents.txt", sep="")
`1995patents` <- read.csv("~/Documents/1995patents.txt", sep="")
`1994patents` <- read.csv("~/Documents/1994patents.txt", sep="")
`1993patents` <- read.csv("~/Documents/1993patents.txt", sep="")
`1992patents` <- read.csv("~/Documents/1992patents.txt", sep="")
patents <- rbind(`2000patents`,`2001patents`,`1999patents`,`1998patents`,`1997patents`,`1996patents`,`1995patents`,`1994patents`,`1993patents`,`1992patents`)
write.csv(patents,"patents90s.csv", row.names = TRUE)
cleaned_patents <- read_csv("~/Desktop/Tech Hubs Research/cleaned_patents.csv")
library(tidyverse)
library(dplyr)
library(data.table)
cleaned_patents <- read_csv("~/Desktop/Tech Hubs Research/cleaned_patents.csv")
View(cleaned_patents)
non_missing_coords<- na.omit(cleaned_patents)
non_missing_coords<- get_metro(non_missing_coords,"inventor_longitude" , "inventor_latitude")
patent_authors <- aggregate(non_missing_coords$inventor_key_id, by=list(non_missing_coords$patent_number), FUN=length)
View(patent_authors)
names(patent_authors)[1] <-'patent_number'
names(patent_authors)[2] <-'authors'
View(patent_authors)
hist(patent_authors$authors)
summarize(patent_authors$authors)
mean(patent_authors$authors)
max(patent_authors$authors)
`Q12017` <- read.csv("/Users/connorobrien/Downloads/Q12017.csv")
View(Q12017)
# Pulling in downloaded data, quarter by quarter from 2017 through 2021.
`Q12017` <- read.csv("/Users/connorobrien/Downloads/Q12017.csv")
`Q22017` <- read.csv("/Users/connorobrien/Downloads/Q22017.csv")
`Q32017` <- read.csv("/Users/connorobrien/Downloads/Q32017.csv")
`Q42017` <- read.csv("/Users/connorobrien/Downloads/Q42017.csv")
`Q12018` <- read.csv("/Users/connorobrien/Downloads/Q12018.csv")
`Q22018` <- read.csv("/Users/connorobrien/Downloads/Q22018.csv")
`Q32018` <- read.csv("/Users/connorobrien/Downloads/Q32018.csv")
`Q42018` <- read.csv("/Users/connorobrien/Downloads/Q42018.csv")
`Q12019` <- read.csv("/Users/connorobrien/Downloads/Q12019.csv")
`Q22019` <- read.csv("/Users/connorobrien/Downloads/Q22019.csv")
`Q32019` <- read.csv("/Users/connorobrien/Downloads/Q32019.csv")
`Q42019` <- read.csv("/Users/connorobrien/Downloads/Q42019.csv")
`Q12020` <- read.csv("/Users/connorobrien/Downloads/Q12020.csv")
`Q22020` <- read.csv("/Users/connorobrien/Downloads/Q22020.csv")
`Q32020` <- read.csv("/Users/connorobrien/Downloads/Q32020.csv")
`Q42020` <- read.csv("/Users/connorobrien/Downloads/Q42020.csv")
`Q12021` <- read.csv("/Users/connorobrien/Downloads/Q12021.csv")
`Q22021` <- read.csv("/Users/connorobrien/Downloads/Q22021.csv")
`Q32021` <- read.csv("/Users/connorobrien/Downloads/Q32021.csv")
`Q42021` <- read.csv("/Users/connorobrien/Downloads/Q42021.csv")
#Combining data and replacing missing values
library(naniar)
patents_since_17 <- rbind(`Q12017`,`Q22017`,`Q32017`,`Q42017`,`Q12018`,`Q22018`,`Q32018`,`Q42018`,`Q12019`,`Q22019`,`Q32019`,`Q42019`,`Q12020`, `Q22020`,`Q32020`,`Q42020`,`Q12021`,`Q22021`,`Q32021`,`Q42021`)
patents_since_17 <- patents_since_17 %>% replace_with_na(replace = list(citedby_patent_number = "None"))
patents_since_17 <- patents_since_17 %>% replace_with_na(replace = list(inventor_latitude = "None"))
patents_since_17 <- patents_since_17 %>% replace_with_na(replace = list(inventor_longitude = "None"))
library(tidyverse)
library(dplyr)
library(data.table)
View(patents_since_17)
write.csv(patents_since_17,"/Users/connorobrien/Downloads/patentsall.csv", row.names = FALSE)
all_authors<- metro_patents <-aggregate(patents_since_17$inventor_key_id, by=list(patents_since_17$inventor_key_id), FUN=length)
patents_since_17_short <- patents_since_17[,2:6]
unique_patents <- unique(patents_since_17_short)
View(unique_patents)
## October 17, 2022: Excluding all patents for which there isn't available data for all authors
all_patents <-aggregate(unique_patents$inventor_key_id, by=list(unique_patents$patent_number), FUN=length)
## October 17, 2022: Excluding all patents for which there isn't available data for all authors
all_patents <-aggregate(unique_patents$inventor_key_id, by=list(unique_patents$patent_number), FUN=length, na.action = pass)
## October 17, 2022: Excluding all patents for which there isn't available data for all authors
all_patents <-aggregate(unique_patents$inventor_key_id, by=list(unique_patents$patent_number), FUN=length, na.action = na.pass)
View(unique_patents)
## October 17, 2022: Excluding all patents for which there isn't available data for all authors
author_count_including_NAs <-aggregate(unique_patents$inventor_key_id, by=list(unique_patents$patent_number), FUN=length, na.action = na.pass)
author_count_invluding_NAs <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(count_authors = n())
author_count_invluding_NAs <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(patent_number = n())
View(author_count_invluding_NAs)
author_count_missing_coords <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(count_na = sum(is.na(unique_patents$latitude)))
View(author_count_missing_coords)
View(unique_patents)
author_count_missing_coords <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(count_na = sum(is.na(unique_patents$longitude)))
View(author_count_missing_coords)
author_count_missing_coords <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(count_na = sum(is.na(unique_patents$longitude)))
View(author_count_missing_coords)
author_count_missing_coords <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(count_na = sum(is.na()))
author_count_missing_coords <- aggregate(unique_patents$patent_number, data=unique_patents, function(x) {sum(is.na(unique_patents$inventor_latitude))}, na.action = NULL)
library(dplyr)
author_count_missing_coords <- unique_patents %>%
group_by(unique_patents$patent_number) %>%
summarise(sum_na = sum(is.na(unique_patents$inventor_latitude)))
author_count_missing_coords <- unique_patents %>%
group_by(unique_patents$patent_number) %>%
summarise(sum_na = sum(is.na(unique_patents$inventor_latitude)))
patents_with_missing_coords <- unique_patents[is.na(unique_patents$inventor_latitude), ]
patent_na_coord_count <- patents_with_missing_coords %>% group_by(unique_patents$patent_number) %>% summarise(inventor_key_id = n())
patent_na_coord_count <- patents_with_missing_coords %>% group_by(patents_with_missing_coords$patent_number) %>% summarise(inventor_key_id = n())
View(patent_na_coord_count)
names(patent_na_coord_count)[2] <-'missing_author_coordinates'
names(patent_na_coord_count)[1] <-'patent_number'
author_count_including_NAs <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(patent_number = n())
patents_na_author_count <- merge(author_count_including_NAs, patent_na_coord_count)
View(patents_na_author_count)
View(author_count_including_NAs)
names(author_count_including_NAs)[1] <-'patent_number'
names(author_count_including_NAs)[2] <-'total_authors'
patents_na_author_count <- merge(author_count_including_NAs, patent_na_coord_count)
View(patents_na_author_count)
patents_na_author_count <- merge(author_count_including_NAs, patent_na_coord_count, all = TRUE)
View(patents_na_author_count)
complete_patents_only <- patents_na_author_count[is.na(patents_na_author_count$missing_author_coordinates),]
View(complete_patents_only)
View(complete_patents_only)
View(patents_since_17)
View(complete_patents_only)
hist(complete_patents_only$total_authors)
mean(complete_patents_only$total_authors)
max(complete_patents_only$total_authors)
min(complete_patents_only$total_authors)
View(complete_patents_only)
complete_patents_only$indicator <- 1
View(complete_patents_only)
patents_plus_indicator <- merge(patents_since_17, complete_patents_only)
View(patents_plus_indicator)
patent_plus_indicator <- patent_plus_indicator %>% mutate(weight = indicator/total_authors)
patents_plus_indicator <- patents_plus_indicator %>% mutate(weight = indicator/total_authors)
View(patents_plus_indicator)
get_metro <- function(data, X, Y) {
data_sf <- sf::st_as_sf(data, coords = c(X, Y),
crs = 4269)
cbsa <- tigris::core_based_statistical_areas() |>
dplyr::select(GEOID, NAME)
sf::st_join(data_sf, cbsa) |>
sf::st_drop_geometry()
}
# get MSAs
patents_plus_indicator<- get_metro(patents_plus_indicator,"inventor_longitude" , "inventor_latitude")
View(patents_plus_indicator)
View(patents_plus_indicator)
# MSA patent totals
patents_without_citations <- patents_plus_indicator[, c(1, 3, 4, 5, 6, 7, 8, 9, 10)]
patents_without_citations <- unique(patents_without_citations)
patents_by_metro <- ggregate(patents_without_citationsr$weight, by=list(patents_without_citations$GEOID), FUN=sum)
patents_by_metro <- aggregate(patents_without_citationsr$weight, by=list(patents_without_citations$GEOID), FUN=sum)
patents_by_metro <- aggregate(patents_without_citations$weight, by=list(patents_without_citations$GEOID), FUN=sum)
View(patents_by_metro)
names(patents_by_metro)[1] <-'GEOID'
names(patents_by_metro)[2] <-'patents_weighted'
patents_by_metro_unweighted <- aggregate(patents_without_citations$patent_number, by=list(patents_without_citations$GEOID), FUN=length)
View(patents_by_metro_unweighted)
names(patents_by_metro_unweighted)[1] <-'GEOID'
names(patents_by_metro_unweighted)[2] <-'patents_unweighted'
patents_by_metro <- merge(patents_by_metro, patents_by_metro_unweighted)
View(patents_by_metro)
write.csv(patents_by_metro, "/Users/connorobrien/Downloads/patentsbymetro.csv", row.names = FALSE)
View(patents_plus_indicator)
# MSA citation totals
patents_cited_only <- patents_plus_indicator %>% drop_xna(citedby_patent_number)
# MSA citation totals
patents_cited_only <- patents_plus_indicator %>% drop_na(citedby_patent_number)
View(patents_cited_only)
citations_by_metro <- aggregate(patents_cited_only$weight, by=list(patents_cited_only$GEOID), FUN=sum)
citations_by_metro_unweighted <- aggregate(patents_cited_only$patent_number, by=list(patents_cited_only$GEOID), FUN=length)
View(citations_by_metro)
names(citations_by_metro)[1] <-'GEOID'
names(citations_by_metro)[2] <-'citations_weighted'
names(citations_by_metro_unweighted)[1] <-'GEOID'
names(citations_by_metro_unweighted)[2] <-'citations_unweighted'
citations_by_metro <- merge(citations_by_metro, citations_by_metro_unweighted)
patents_by_metro <- merge(patents_by_metro, citations_by_metro)
View(patents_by_metro)
write.csv(patents_by_metro, "/Users/connorobrien/Downloads/patentsbymetro.csv", row.names = FALSE)
View(complete_patents_only)
View(patents_plus_indicator)
# Authors
patents_plus_indicator$patent_date<-as.Date(patents_plus_indicator$patent_date)
patents_plus_indicator <- patents_plus_indicator[order(patents_plus_indicator$patent_date, decreasing = TRUE),]
View(patents_plus_indicator)
# Authors
patents_without_citations$patent_date<-as.Date(patents_without_citations$patent_date)
patents_without_citations <- patents_without_citations[order(patents_without_citations$patent_date, decreasing = TRUE),]
View(patents_without_citations)
authors <- distinct(patents_without_citations, inventor_key_id, .keep_all = TRUE)
View(authors)
authors <- aggregate(authors$inventor_key_id, by=list(patents_cited_only$GEOID), FUN=length)
authors <- aggregate(authors$inventor_key_id, by=list(authors$GEOID), FUN=length)
View(authors)
names(authors)[1] <-'GEOID'
names(authors)[2] <-'authors'
patents_by_metro <- merge(patents_by_metro, authors)
View(patents_by_metro)
write.csv(patents_by_metro, "/Users/connorobrien/Downloads/patentsbymetro.csv", row.names = FALSE)
View(patents_by_metro)
patents_plus_indicator<- get_metro(patents_plus_indicator,"inventor_longitude" , "inventor_latitude")
View(patents_plus_indicator)
which(patents_plus_indicator == "Grand Forks", arr.ind = TRUE)
View(patents_since_17)
View(patents_since_17)
################################################################
## October 17, 2022: Excluding all patents for which there isn't available data for all authors
author_count_including_NAs <-aggregate(unique_patents$inventor_key_id, by=list(unique_patents$patent_number), FUN=length, na.action = na.pass)
################################################################
## October 17, 2022: Excluding all patents for which there isn't available data for all authors
author_count_including_NAs <-aggregate(unique_patents$inventor_key_id, by=list(unique_patents$patent_number), FUN=length, na.action = na.pass)
author_count_including_NAs <-aggregate(unique_patents$inventor_key_id, by=list(unique_patents$patent_number), FUN=length, na.action = na.pass)
View(author_count_including_NAs)
# Calculating how many authors for each patent are missing coordinates
author_count_including_NAs <- unique_patents %>% group_by(unique_patents$patent_number) %>% summarise(patent_number = n())
patents_with_missing_coords <- unique_patents[is.na(unique_patents$inventor_latitude), ]
patent_na_coord_count <- patents_with_missing_coords %>% group_by(patents_with_missing_coords$patent_number) %>% summarise(inventor_key_id = n())
names(patent_na_coord_count)[2] <-'missing_author_coordinates'
names(patent_na_coord_count)[1] <-'patent_number'
names(author_count_including_NAs)[1] <-'patent_number'
names(author_count_including_NAs)[2] <-'total_authors'
patents_na_author_count <- merge(author_count_including_NAs, patent_na_coord_count, all = TRUE)
complete_patents_only <- patents_na_author_count[is.na(patents_na_author_count$missing_author_coordinates),]
complete_patents_only$indicator <- 1
# merge and create author weight
patents_plus_indicator <- merge(patents_since_17, complete_patents_only)
patents_plus_indicator <- patents_plus_indicator %>% mutate(weight = indicator/total_authors)
# get MSAs
patents_plus_indicator<- get_metro(patents_plus_indicator,"inventor_longitude" , "inventor_latitude")
# MSA patent totals
patents_without_citations <- patents_plus_indicator[, c(1, 3, 4, 5, 6, 7, 8, 9, 10)]
patents_without_citations <- unique(patents_without_citations)
patents_by_metro <- aggregate(patents_without_citations$weight, by=list(patents_without_citations$GEOID), FUN=sum)
View(patents_by_metro)
names(patents_by_metro)[1] <-'GEOID'
names(patents_by_metro)[2] <-'patents_weighted'
patents_by_metro_unweighted <- aggregate(patents_without_citations$patent_number, by=list(patents_without_citations$GEOID), FUN=length)
names(patents_by_metro_unweighted)[1] <-'GEOID'
names(patents_by_metro_unweighted)[2] <-'patents_unweighted'
patents_by_metro <- merge(patents_by_metro, patents_by_metro_unweighted)
write.csv(patents_by_metro, "/Users/connorobrien/Downloads/patentsbymetro.csv", row.names = FALSE)
# MSA citation totals
patents_cited_only <- patents_plus_indicator %>% drop_na(citedby_patent_number)
citations_by_metro <- aggregate(patents_cited_only$weight, by=list(patents_cited_only$GEOID), FUN=sum)
citations_by_metro_unweighted <- aggregate(patents_cited_only$patent_number, by=list(patents_cited_only$GEOID), FUN=length)
names(citations_by_metro)[1] <-'GEOID'
names(citations_by_metro)[2] <-'citations_weighted'
names(citations_by_metro_unweighted)[1] <-'GEOID'
names(citations_by_metro_unweighted)[2] <-'citations_unweighted'
patents_by_metro <- merge(patents_by_metro, citations_by_metro, all = TRUE)
View(patents_by_metro)
patents_by_metro <- merge(patents_by_metro, authors, all = TRUE)
View(patents_by_metro)
write.csv(patents_by_metro, "/Users/connorobrien/Downloads/patentsbymetro.csv", row.names = FALSE)
write.csv(patents_by_metro, "/Users/connorobrien/Downloads/patentsbymetro.csv", row.names = FALSE)
View(patents_plus_indicator)
citations_by_metro <- merge(citations_by_metro, citations_by_metro_unweighted)
patents_by_metro <- merge(patents_by_metro, patents_by_metro_unweighted)
patents_by_metro <- aggregate(patents_without_citations$weight, by=list(patents_without_citations$GEOID), FUN=sum)
names(patents_by_metro)[1] <-'GEOID'
names(patents_by_metro)[2] <-'patents_weighted'
patents_by_metro_unweighted <- aggregate(patents_without_citations$patent_number, by=list(patents_without_citations$GEOID), FUN=length)
names(patents_by_metro_unweighted)[1] <-'GEOID'
names(patents_by_metro_unweighted)[2] <-'patents_unweighted'
patents_by_metro <- merge(patents_by_metro, patents_by_metro_unweighted)
View(patents_by_metro)
# MSA citation totals
patents_cited_only <- patents_plus_indicator %>% drop_na(citedby_patent_number)
citations_by_metro <- aggregate(patents_cited_only$weight, by=list(patents_cited_only$GEOID), FUN=sum)
citations_by_metro_unweighted <- aggregate(patents_cited_only$patent_number, by=list(patents_cited_only$GEOID), FUN=length)
names(citations_by_metro)[1] <-'GEOID'
names(citations_by_metro)[2] <-'citations_weighted'
names(citations_by_metro_unweighted)[1] <-'GEOID'
names(citations_by_metro_unweighted)[2] <-'citations_unweighted'
citations_by_metro <- merge(citations_by_metro, citations_by_metro_unweighted)
patents_by_metro <- merge(patents_by_metro, citations_by_metro, all = TRUE)
View(patents_by_metro)
patents_by_metro <- merge(patents_by_metro, authors, all = TRUE)
write.csv(patents_by_metro, "/Users/connorobrien/Downloads/patentsbymetro.csv", row.names = FALSE)
# Install necessary packages
install.packages("readxl")
install.packages("tidyverse")
# Load packages
library(readxl)
library(tidyverse)
# Set the URL for the BLS jobs data
url <- "https://www.bls.gov/web/empsit/cpseea29.xls"
# Read the data from the URL into a data frame
jobs_data <- read_excel(url)
# Use the select function from the tidyverse package to select only the columns we want
jobs_data <- select(jobs_data, month, year, total_nonfarm_jobs)
# Install necessary packages
install.packages("quantmod")
# Load packages
library(quantmod)
# Set the start and end dates for the data
start_date <- as.Date("1980-01-01")
end_date <- as.Date("today")
# Use the getSymbols function from the quantmod package to pull the data for the S&P 500 Index
sp500 <- getSymbols("^GSPC", src="yahoo", from=start_date, to=end_date, auto.assign=FALSE)
# Use the Ad function from the quantmod package to get the adjusted closing prices
sp500_adj_close <- Ad(sp500)
# Use the to.data.frame function to convert the adjusted closing prices to a data frame
sp500_df <- to.data.frame(sp500_adj_close)
# Rename the columns to something more descriptive
colnames(sp500_df) <- c("date", "adj_close")
# Load packages
library(ggplot2)
# Set the URL for the data from the paper
url <- "https://www.princeton.edu/~card/data/NJ-PA.xls"
# Read the data from the URL into a data frame
minimum_wage_data <- read_excel(url, sheet = 1)
# Use the filter function from the dplyr package to select only the data for New Jersey and Pennsylvania
minimum_wage_data <- filter(minimum_wage_data, state %in% c("New Jersey", "Pennsylvania"))
# Use the mutate function from the dplyr package to create a new column for the log of employment
minimum_wage_data <- mutate(minimum_wage_data, log_employment = log(employment))
# Use the ggplot function from the ggplot2 package to create a scatterplot of the data
ggplot(minimum_wage_data, aes(x = log_minimum_wage, y = log_employment)) +
geom_point(aes(color = state)) +
geom_smooth(method = "lm", se = FALSE)
# Define the number of buyers and sellers in the market
n_buyers <- 100
n_sellers <- 100
# Define the demand and supply functions for the market
demand_func <- function(price) {
a * price^(-b)
}
supply_func <- function(price) {
c * price^d
}
# Estimate the parameters of the demand and supply functions
demand_params <- lm(demand ~ price, data = market_data)$coefficients
supply_params <- lm(supply ~ price, data = market_data)$coefficients
# Calculate the equilibrium price and quantity in the market
equilibrium_price <- uniroot(demand_func - supply_func, c(0, max(market_data$price)))$root
equilibrium_quantity <- demand_func(equilibrium_price)
# Simulate the market by generating random shocks to the demand and supply functions
n_simulations <- 1000
demand_shocks <- rnorm(n_simulations, 0, 0.1)
supply_shocks <- rnorm(n_simulations, 0, 0.1)
simulation_results <- data.frame(
price = numeric(n_simulations),
quantity = numeric(n_simulations)
)
for (i in 1:n_simulations) {
# Calculate the new demand and supply functions with the random shocks
demand_func_shock <- function(price) {
demand_func(price) * (1 + demand_shocks[i])
}
supply_func_shock <- function(price) {
supply_func(price) * (1 + supply_shocks[i])
}
# Calculate the new equilibrium values with the random shocks
simulation_results$price[i] <- uniroot(demand_func_shock - supply_func_shock, c(0, max(market_data$price)))
View(simulation_results)
View(simulation_results)
View(simulation_results)
View(simulation_results)
simulation_results
view(simulation_results)
print(simulation_results)
library(tidyverse)
library(readxl)
# Importing H1B LCA Data from 2021
# Q1 2021
url <- "https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/LCA_Disclosure_Data_FY2021_Q1.xlsx"
destfile <- "LCA_Disclosure_Data_FY2021_Q1.xlsx"
curl::curl_download(url, destfile)
LCA_Disclosure_Data_FY2021_Q1 <- read_excel(destfile)
# Q2 2022
url <- "https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/LCA_Disclosure_Data_FY2021_Q2.xlsx"
destfile <- "LCA_Disclosure_Data_FY2021_Q2.xlsx"
curl::curl_download(url, destfile)
LCA_Disclosure_Data_FY2021_Q2<- read_excel(destfile)
url <- "https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/LCA_Disclosure_Data_FY2021_Q3.xlsx"
destfile <- "LCA_Disclosure_Data_FY2021_Q3.xlsx"
curl::curl_download(url, destfile)
LCA_Disclosure_Data_FY2021_Q3<- read_excel(destfile)
url <- "https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/LCA_Disclosure_Data_FY2021_Q4.xlsx"
destfile <- "LCA_Disclosure_Data_FY2021_Q4.xlsx"
curl::curl_download(url, destfile)
LCA_Disclosure_Data_FY2021_Q4<- read_excel(destfile)
LCAs_2021 <- rbind(LCA_Disclosure_Data_FY2021_Q1, LCA_Disclosure_Data_FY2021_Q2, LCA_Disclosure_Data_FY2021_Q3, LCA_Disclosure_Data_FY2021_Q4)
View(LCA_Disclosure_Data_FY2021_Q1)
LCAs_2021 <- rbind(LCA_Disclosure_Data_FY2021_Q1, LCA_Disclosure_Data_FY2021_Q2)
library(dplyr)
LCAs_2021 <- bind_rows(LCA_Disclosure_Data_FY2021_Q1, LCA_Disclosure_Data_FY2021_Q2, LCA_Disclosure_Data_FY2021_Q3, LCA_Disclosure_Data_FY2021_Q4)
rlang::last_error()
LCA_Disclosure_Data_FY2021_Q3$EMPLOYER_PHONE<- as.character(LCA_Disclosure_Data_FY2021_Q3$EMPLOYER_PHONE)
LCAs_2021 <- bind_rows(LCA_Disclosure_Data_FY2021_Q1, LCA_Disclosure_Data_FY2021_Q2, LCA_Disclosure_Data_FY2021_Q3, LCA_Disclosure_Data_FY2021_Q4)
LCA_Disclosure_Data_FY2021_Q3$EMPLOYER_POC_PHONE<- as.character(LCA_Disclosure_Data_FY2021_Q3$EMPLOYER_POC_PHONE)
LCAs_2021 <- bind_rows(LCA_Disclosure_Data_FY2021_Q1, LCA_Disclosure_Data_FY2021_Q2, LCA_Disclosure_Data_FY2021_Q3, LCA_Disclosure_Data_FY2021_Q4)
LCA_Q1 <- LCA_Disclosure_Data_FY2021_Q1[1:20, 24:25,31, 72:90]
View(LCA_Q1)
LCA_Q1 <- LCA_Disclosure_Data_FY2021_Q1[,1:20, 24:25,31, 72:90]
LCA_Q2 <- LCA_Disclosure_Data_FY2021_Q2[,1:20, 24:25,31, 72:90]
LCA_Q3 <- LCA_Disclosure_Data_FY2021_Q3[,1:20, 24:25,31, 72:90]
LCA_Q4 <- LCA_Disclosure_Data_FY2021_Q4[,1:20, 24:25,31, 72:90]
# Merge into 2021 file
LCAs_2021 <- bind_rows(LCA_Q1, LCA_Q2, LCA_Q3, LCA_Q4)
View(LCAs_2021)
LCAs_2021_H1B <- LCAs_2021%>% filter(VISA_CLASS=="H-1B")
LCAs_2021_H1B <- LCAs_2021%>% filter(CASE_STATUS=="Certified")
View(LCAs_2021_H1B)
LCAs_2021 <- bind_rows(LCA_Q1, LCA_Q2, LCA_Q3, LCA_Q4)
LCAs_2021_H1B <- LCAs_2021%>% filter(VISA_CLASS=="H-1B")
View(LCAs_2021_H1B)
LCAs_2021_H1B <- LCAs_2021%>% filter(CASE_STATUS=="Certified" | CASE_STATUS=="Certified - Withdrawn")
View(LCAs_2021_H1B)
View(LCAs_2021_H1B)
View(LCA_Disclosure_Data_FY2021_Q4)
View(LCA_Q3)
View(LCA_Q1)
View(LCAs_2021_H1B)
summarize(LCAs_2021_H1B$NEW_EMPLOYMENT)
summarise(LCAs_2021_H1B$NEW_EMPLOYMENT)
LCAs_2021_H1B %>% summarise(NEW_EMPLOYMENT)
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT))
View(LCA_Q1)
LCA_Q1 <- LCA_Disclosure_Data_FY2021_Q1 %>% select(1:20, 24:25,31, 72:90)
LCA_Q2 <- LCA_Disclosure_Data_FY2021_Q2 %>% select(1:20, 24:25,31, 72:90)
LCA_Q3 <- LCA_Disclosure_Data_FY2021_Q3 %>% select(1:20, 24:25,31, 72:90)
LCA_Q4 <- LCA_Disclosure_Data_FY2021_Q4 %>% select(1:20, 24:25,31, 72:90)
# Merge into 2021 file
LCAs_2021 <- bind_rows(LCA_Q1, LCA_Q2, LCA_Q3, LCA_Q4)
LCAs_2021_H1B <- LCAs_2021%>% filter(VISA_CLASS=="H-1B")
# Merge into 2021 file
LCAs_2021 <- bind_rows(LCA_Q1, LCA_Q2, LCA_Q3, LCA_Q4)
View(LCAs_2021_H1B)
LCAs_2021_H1B %>% summarise(sum(TOTAL_WORKER_POSITIONS))
LCAs_2021_H1B %>% summarise(sum(NEW_CONCURRENT_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(sum(CHANGE_PREVIOUS_EMPLOYMENT))
View(LCAs_2021_H1B)
LCAs_2021_H1B <- LCAs_2021%>% filter(VISA_CLASS=="H-1B")
LCAs_2021_H1B <- LCAs_2021%>% filter(CASE_STATUS=="Certified" | CASE_STATUS=="Certified - Withdrawn")
View(LCAs_2021_H1B)
LCAs_2021_H1B %>% summarise(sum(CHANGE_PREVIOUS_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(max(CHANGE_PREVIOUS_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(min(CHANGE_PREVIOUS_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(mean(CHANGE_PREVIOUS_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT))
View(LCAs_2021_H1B)
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT)/(sum(CHANGE_EMPLOYER)+sum(NEW_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT)/(sum(CHANGE_EMPLOYER)+sum(NEW_EMPLOYMENT)))
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(sum(CHANGE_EMPLOYER))
297330/(637051+237330)
297330/805988
297330/637051
View(LCA_Disclosure_Data_FY2021_Q1)
View(LCAs_2021_H1B)
LCAs_2021_H1B <- LCAs_2021%>% filter(VISA_CLASS=="H-1B")
View(LCAs_2021_H1B)
LCAs_2021_H1B %>% group_by(VISA_CLASS) %>% summarise()
View(LCA_Disclosure_Data_FY2021_Q3)
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT))
View(LCAs_2021_H1B)
LCAs_2021_H1B %>% summarise(sum(TOTAL_WORKER_POSITIONS))
View(LCAs_2021_H1B)
LCAs_2021_H1B %>% group_by(NEW_EMPLOYMENT) %>% summarise()
library(tidyverse)
library(readxl)
library(dplyr)
LCAs_2021_H1B %>% group_by(NEW_EMPLOYMENT) %>% summarise()
LCAs_2021_H1B %>% group_by(NEW_EMPLOYMENT) %>% aggregate()
LCAs_2021_H1B %>% group_by(NEW_EMPLOYMENT) %>% summarise()
LCAs_2021_H1B %>% summarise(sum(TOTAL_WORKER_POSITIONS))
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT))
View(LCAs_2021_H1B)
facebook_H1Bs <- LCAs_2021_H1B %>% filter(EMPLOYER_NAME== "FACEBOOK INC.")
View(facebook_H1Bs)
LCAs_2021_H1B %>% summarise(sum(NEW_EMPLOYMENT))
LCAs_2021_H1B %>% summarise(sum(CHANGE_EMPLOYER)
LCAs_2021_H1B %>% summarise(sum(CHANGE_EMPLOYER))
LCAs_2021_H1B %>% summarise(sum(CHANGE_EMPLOYER))
636605-301128
LCAs_2021_H1B_certified <- LCAs_2021%>% filter(CASE_STATUS=="Certified")
LCAs_2021_H1B_certified %>% summarise(sum(NEW_EMPLOYMENT))
LCAs_2021_H1B_certified %>% summarise(sum(CHANGE_EMPLOYER))
610031-288829
LCAs_2021_H1B_certified %>% summarise(sum(NEW_CONCURRENT_EMPLOYMENT))
library(readxl)
PERM_FY2019 <- read_excel("Downloads/PERM_FY2019.xlsx")
View(PERM_FY2019)
library(tidyverse)
library(dplyr)
View(PERM_FY2019)
library(censusapi)
install.packages("censusapi")
library(censusapi)
Sys.info()[["user"]]
setwd("~/Documents/GitHub/BDS-hightech")
if(Sys.info()[["user"]]=="connorobrien"){
# Root folder
path_project <- "/Documents"
}
# Path to saved cohort data
path_bds <- paste0(path_project,"/GitHub/BDS-hightech")
setwd(path_bds)
if(Sys.info()[["user"]]=="connorobrien"){
# Root folder
path_project <- "~/Documents"
}
# Path to saved cohort data
path_bds <- paste0(path_project,"/GitHub/BDS-hightech")
setwd(path_bds)
